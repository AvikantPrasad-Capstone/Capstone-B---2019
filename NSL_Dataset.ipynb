{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import metrics\n",
    "from keras.layers.core import Dense, Activation\n",
    "import pandas\n",
    "from keras.layers import Dropout\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach the column names to the dataset\n",
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"NSL_Dataset.csv\", header=None, names = col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into features and outcomes\n",
    "\n",
    "x = df.drop(['label'], axis = 1 )\n",
    "y = df[['label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn categorical data into dummy variables \n",
    "\n",
    "dummies_1= pd.get_dummies(x['protocol_type'])\n",
    "dummies_2 = pd.get_dummies(x['service'])\n",
    "dummies_3 = pd.get_dummies(x['flag'])\n",
    "\n",
    "x = x.drop(['protocol_type','service','flag'], axis = 1)\n",
    "\n",
    "#x = x.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pandas.concat([x, dummies_1], axis = 'columns')\n",
    "\n",
    "#dummy variable trap \n",
    "x = merged.drop(['icmp'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_1= pandas.concat([x, dummies_2], axis = 'columns')\n",
    "\n",
    "#dummy variable trap \n",
    "\n",
    "x = merged_1.drop(['whois'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_2= pandas.concat([x, dummies_3], axis = 'columns')\n",
    "\n",
    "x = merged_2.drop(['SH'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>OTH</th>\n",
       "      <th>REJ</th>\n",
       "      <th>RSTO</th>\n",
       "      <th>RSTOS0</th>\n",
       "      <th>RSTR</th>\n",
       "      <th>S0</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>SF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125969</td>\n",
       "      <td>8</td>\n",
       "      <td>105</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125970</td>\n",
       "      <td>0</td>\n",
       "      <td>2231</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125972</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125973 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0              0        491          0     0               0       0    0   \n",
       "1              0        146          0     0               0       0    0   \n",
       "2              0          0          0     0               0       0    0   \n",
       "3              0        232       8153     0               0       0    0   \n",
       "4              0        199        420     0               0       0    0   \n",
       "...          ...        ...        ...   ...             ...     ...  ...   \n",
       "125968         0          0          0     0               0       0    0   \n",
       "125969         8        105        145     0               0       0    0   \n",
       "125970         0       2231        384     0               0       0    0   \n",
       "125971         0          0          0     0               0       0    0   \n",
       "125972         0        151          0     0               0       0    0   \n",
       "\n",
       "        num_failed_logins  logged_in  num_compromised  ...  OTH  REJ  RSTO  \\\n",
       "0                       0          0                0  ...    0    0     0   \n",
       "1                       0          0                0  ...    0    0     0   \n",
       "2                       0          0                0  ...    0    0     0   \n",
       "3                       0          1                0  ...    0    0     0   \n",
       "4                       0          1                0  ...    0    0     0   \n",
       "...                   ...        ...              ...  ...  ...  ...   ...   \n",
       "125968                  0          0                0  ...    0    0     0   \n",
       "125969                  0          0                0  ...    0    0     0   \n",
       "125970                  0          1                0  ...    0    0     0   \n",
       "125971                  0          0                0  ...    0    0     0   \n",
       "125972                  0          1                0  ...    0    0     0   \n",
       "\n",
       "        RSTOS0  RSTR  S0  S1  S2  S3  SF  \n",
       "0            0     0   0   0   0   0   1  \n",
       "1            0     0   0   0   0   0   1  \n",
       "2            0     0   1   0   0   0   0  \n",
       "3            0     0   0   0   0   0   1  \n",
       "4            0     0   0   0   0   0   1  \n",
       "...        ...   ...  ..  ..  ..  ..  ..  \n",
       "125968       0     0   1   0   0   0   0  \n",
       "125969       0     0   0   0   0   0   1  \n",
       "125970       0     0   0   0   0   0   1  \n",
       "125971       0     0   1   0   0   0   0  \n",
       "125972       0     0   0   0   0   0   1  \n",
       "\n",
       "[125973 rows x 119 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>OTH</th>\n",
       "      <th>REJ</th>\n",
       "      <th>RSTO</th>\n",
       "      <th>RSTOS0</th>\n",
       "      <th>RSTR</th>\n",
       "      <th>S0</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>SF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007679</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019113</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>-0.618438</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>0.825150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019113</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>-0.618438</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>0.825150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019113</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>1.616978</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-1.211901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007723</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019113</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>-0.618438</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>0.825150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007728</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019113</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>-0.618438</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>0.825150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes      land  wrong_fragment    urgent  \\\n",
       "0 -0.110249  -0.007679  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "1 -0.110249  -0.007737  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "2 -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "3 -0.110249  -0.007723  -0.002891 -0.014089       -0.089486 -0.007736   \n",
       "4 -0.110249  -0.007728  -0.004814 -0.014089       -0.089486 -0.007736   \n",
       "\n",
       "        hot  num_failed_logins  logged_in  num_compromised  ...       OTH  \\\n",
       "0 -0.095076          -0.027023  -0.809262        -0.011664  ... -0.019113   \n",
       "1 -0.095076          -0.027023  -0.809262        -0.011664  ... -0.019113   \n",
       "2 -0.095076          -0.027023  -0.809262        -0.011664  ... -0.019113   \n",
       "3 -0.095076          -0.027023   1.235694        -0.011664  ... -0.019113   \n",
       "4 -0.095076          -0.027023   1.235694        -0.011664  ... -0.019113   \n",
       "\n",
       "        REJ     RSTO    RSTOS0      RSTR        S0        S1        S2  \\\n",
       "0 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906 -0.031767   \n",
       "1 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906 -0.031767   \n",
       "2 -0.312889 -0.11205 -0.028606 -0.139982  1.616978 -0.053906 -0.031767   \n",
       "3 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906 -0.031767   \n",
       "4 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906 -0.031767   \n",
       "\n",
       "         S3        SF  \n",
       "0 -0.019726  0.825150  \n",
       "1 -0.019726  0.825150  \n",
       "2 -0.019726 -1.211901  \n",
       "3 -0.019726  0.825150  \n",
       "4 -0.019726  0.825150  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get column names first\n",
    "names = x.columns\n",
    "# Create the Scaler object\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# Fit data on the scaler object\n",
    "scaled_df = scaler.fit_transform(x)\n",
    "new_scaled_df = pd.DataFrame(scaled_df, columns=names)\n",
    "\n",
    "x = pd.DataFrame(new_scaled_df)\n",
    "\n",
    "x[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape:    (125973, 119)\n",
      "Transformed Shape: (125973, 2)\n",
      "[[-1.00608009 -0.1913688 ]\n",
      " [-0.26121248  1.41682502]\n",
      " [ 4.36869711 -1.68757589]\n",
      " ...\n",
      " [-0.87299452 -0.71870499]\n",
      " [ 4.50750309 -1.92864967]\n",
      " [-1.50163837 -0.45250432]]\n"
     ]
    }
   ],
   "source": [
    "#Perform PCA to reduce dimensionality of feature vector for better accuracy\n",
    "#reduce from 119 to 2 dimensional space\n",
    "\n",
    "pca=PCA(n_components = 2)\n",
    "pca.fit(x)\n",
    "x_scaled = pca.transform(x)\n",
    "print (\"Original Shape:   \", x.shape)\n",
    "print (\"Transformed Shape:\",x_scaled.shape)\n",
    "\n",
    "x = x_scaled\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn malicious packets into true and normal into false\n",
    "\n",
    "y['Target'] = y['label'] != 'normal'\n",
    "y = y.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Turn Outcomes into dummy variables \n",
    "\n",
    "dummies = pd.get_dummies(y['Target'])\n",
    "\n",
    "# This will turn BENIGN values into 1 being False and all malicious packets into 0 being True. \n",
    "y = dummies.values\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into test and training sets. 20% test sample \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source":[]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100778 samples, validate on 25195 samples\n",
      "Epoch 1/100\n",
      "100778/100778 [==============================] - 10s 101us/step - loss: 0.3554 - acc: 0.8824 - val_loss: 0.1779 - val_acc: 0.9257\n",
      "Epoch 2/100\n",
      "100778/100778 [==============================] - 9s 91us/step - loss: 0.2054 - acc: 0.9142 - val_loss: 0.1688 - val_acc: 0.9269\n",
      "Epoch 3/100\n",
      "100778/100778 [==============================] - 8s 81us/step - loss: 0.1885 - acc: 0.9208 - val_loss: 0.1650 - val_acc: 0.9242\n",
      "Epoch 4/100\n",
      "100778/100778 [==============================] - 8s 82us/step - loss: 0.1787 - acc: 0.9260 - val_loss: 0.1577 - val_acc: 0.9301\n",
      "Epoch 5/100\n",
      "100778/100778 [==============================] - 8s 82us/step - loss: 0.1724 - acc: 0.9280 - val_loss: 0.1559 - val_acc: 0.9313\n",
      "Epoch 6/100\n",
      "100778/100778 [==============================] - 9s 89us/step - loss: 0.1664 - acc: 0.9315 - val_loss: 0.1511 - val_acc: 0.9329\n",
      "Epoch 7/100\n",
      "100778/100778 [==============================] - 9s 88us/step - loss: 0.1636 - acc: 0.9327 - val_loss: 0.1487 - val_acc: 0.9348\n",
      "Epoch 8/100\n",
      "100778/100778 [==============================] - 9s 86us/step - loss: 0.1603 - acc: 0.9339 - val_loss: 0.1476 - val_acc: 0.9347\n",
      "Epoch 9/100\n",
      "100778/100778 [==============================] - 8s 84us/step - loss: 0.1580 - acc: 0.9343 - val_loss: 0.1481 - val_acc: 0.9356\n",
      "Epoch 10/100\n",
      "100778/100778 [==============================] - 8s 84us/step - loss: 0.1572 - acc: 0.9350 - val_loss: 0.1476 - val_acc: 0.9353\n",
      "Epoch 11/100\n",
      "100778/100778 [==============================] - 8s 84us/step - loss: 0.1550 - acc: 0.9357 - val_loss: 0.1466 - val_acc: 0.9360\n",
      "Epoch 12/100\n",
      "100778/100778 [==============================] - 9s 88us/step - loss: 0.1532 - acc: 0.9360 - val_loss: 0.1475 - val_acc: 0.9347\n",
      "Epoch 13/100\n",
      "100778/100778 [==============================] - 9s 88us/step - loss: 0.1526 - acc: 0.9360 - val_loss: 0.1466 - val_acc: 0.9354\n",
      "Epoch 14/100\n",
      "100778/100778 [==============================] - 9s 88us/step - loss: 0.1515 - acc: 0.9368 - val_loss: 0.1445 - val_acc: 0.9358\n",
      "Epoch 15/100\n",
      "100778/100778 [==============================] - 9s 88us/step - loss: 0.1509 - acc: 0.9365 - val_loss: 0.1442 - val_acc: 0.9367\n",
      "Epoch 16/100\n",
      "100778/100778 [==============================] - 9s 89us/step - loss: 0.1503 - acc: 0.9371 - val_loss: 0.1441 - val_acc: 0.9372\n",
      "Epoch 17/100\n",
      "100778/100778 [==============================] - 8s 84us/step - loss: 0.1492 - acc: 0.9372 - val_loss: 0.1458 - val_acc: 0.9362\n",
      "Epoch 18/100\n",
      "100778/100778 [==============================] - 8s 83us/step - loss: 0.1478 - acc: 0.9376 - val_loss: 0.1430 - val_acc: 0.9362\n",
      "Epoch 19/100\n",
      "100778/100778 [==============================] - 9s 87us/step - loss: 0.1474 - acc: 0.9376 - val_loss: 0.1452 - val_acc: 0.9363\n",
      "Epoch 20/100\n",
      "100778/100778 [==============================] - 9s 87us/step - loss: 0.1469 - acc: 0.9377 - val_loss: 0.1425 - val_acc: 0.9365\n",
      "Epoch 21/100\n",
      "100778/100778 [==============================] - 9s 89us/step - loss: 0.1463 - acc: 0.9380 - val_loss: 0.1431 - val_acc: 0.9367\n",
      "Epoch 22/100\n",
      "100778/100778 [==============================] - 9s 89us/step - loss: 0.1456 - acc: 0.9380 - val_loss: 0.1451 - val_acc: 0.9364\n",
      "Epoch 23/100\n",
      "100778/100778 [==============================] - 9s 89us/step - loss: 0.1459 - acc: 0.9382 - val_loss: 0.1421 - val_acc: 0.9365\n",
      "Epoch 24/100\n",
      "100778/100778 [==============================] - 9s 89us/step - loss: 0.1444 - acc: 0.9385 - val_loss: 0.1447 - val_acc: 0.9358\n",
      "Epoch 25/100\n",
      "100778/100778 [==============================] - 9s 89us/step - loss: 0.1446 - acc: 0.9382 - val_loss: 0.1430 - val_acc: 0.9369\n",
      "Epoch 26/100\n",
      "100778/100778 [==============================] - 9s 89us/step - loss: 0.1439 - acc: 0.9386 - val_loss: 0.1418 - val_acc: 0.9364\n",
      "Epoch 27/100\n",
      "100778/100778 [==============================] - 9s 89us/step - loss: 0.1437 - acc: 0.9382 - val_loss: 0.1404 - val_acc: 0.9369\n",
      "Epoch 28/100\n",
      "100778/100778 [==============================] - 9s 89us/step - loss: 0.1429 - acc: 0.9381 - val_loss: 0.1372 - val_acc: 0.9372\n",
      "Epoch 29/100\n",
      "100778/100778 [==============================] - 8s 83us/step - loss: 0.1430 - acc: 0.9383 - val_loss: 0.1394 - val_acc: 0.9366\n",
      "Epoch 30/100\n",
      "100778/100778 [==============================] - 8s 83us/step - loss: 0.1418 - acc: 0.9385 - val_loss: 0.1393 - val_acc: 0.9365\n",
      "Epoch 31/100\n",
      "100778/100778 [==============================] - 9s 85us/step - loss: 0.1417 - acc: 0.9386 - val_loss: 0.1359 - val_acc: 0.9368\n",
      "Epoch 32/100\n",
      "100778/100778 [==============================] - 9s 86us/step - loss: 0.1406 - acc: 0.9387 - val_loss: 0.1356 - val_acc: 0.9372\n",
      "Epoch 33/100\n",
      "100778/100778 [==============================] - 9s 89us/step - loss: 0.1402 - acc: 0.9385 - val_loss: 0.1373 - val_acc: 0.9369\n",
      "Epoch 34/100\n",
      "100778/100778 [==============================] - 9s 89us/step - loss: 0.1398 - acc: 0.9389 - val_loss: 0.1352 - val_acc: 0.9365\n",
      "Epoch 35/100\n",
      "100778/100778 [==============================] - 9s 90us/step - loss: 0.1399 - acc: 0.9384 - val_loss: 0.1351 - val_acc: 0.9369\n",
      "Epoch 36/100\n",
      "100778/100778 [==============================] - 10s 94us/step - loss: 0.1391 - acc: 0.9386 - val_loss: 0.1381 - val_acc: 0.9366\n",
      "Epoch 37/100\n",
      "100778/100778 [==============================] - 9s 90us/step - loss: 0.1386 - acc: 0.9385 - val_loss: 0.1321 - val_acc: 0.9368\n",
      "Epoch 38/100\n",
      "100778/100778 [==============================] - 9s 87us/step - loss: 0.1383 - acc: 0.9385 - val_loss: 0.1340 - val_acc: 0.9373\n",
      "Epoch 39/100\n",
      "100778/100778 [==============================] - 9s 88us/step - loss: 0.1383 - acc: 0.9388 - val_loss: 0.1330 - val_acc: 0.9364\n",
      "Epoch 40/100\n",
      "100778/100778 [==============================] - 9s 88us/step - loss: 0.1374 - acc: 0.9389 - val_loss: 0.1334 - val_acc: 0.9374\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00040: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Create Neural Network, with 4 hidden layers and 2 output layers being subjected to the softmax probability function\n",
    "# and 2 input layers which was reduced by PCA\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(200, input_dim = x.shape[1], activation='relu', kernel_initializer= initializers.he_normal(seed=0.1), bias_initializer = initializers.Constant(0.3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(160, input_dim = x.shape[1], activation='relu', kernel_initializer= initializers.he_normal(seed=0.1),bias_initializer = initializers.Constant(0.3), )) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(120, input_dim = x.shape[1], activation='relu', kernel_initializer= initializers.he_normal(seed=0.1),bias_initializer = initializers.Constant(0.3), ))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(60, input_dim = x.shape[1], activation='relu', kernel_initializer= initializers.he_normal(seed=0.1),bias_initializer = initializers.Constant(0.3), ))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1],activation='softmax')) #takes in an input and spits out 1D vector\n",
    "\n",
    "optimizer = Adam(lr=1e-4, beta_1=0.99, beta_2=0.999)\n",
    "\n",
    "#Add in hyper parameters\n",
    "model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer = optimizer )\n",
    "#Early stopping used to stop model from over or under fitting - stops when accuracy is no longer improving \n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=3, verbose=3, mode='auto', restore_best_weights=True, baseline=None)\n",
    "#Fit the model\n",
    "history = model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=1,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure accuracy\n",
    "predictors = model.predict(x_test)\n",
    "predictors = np.argmax(predictors,axis=1)\n",
    "prediction = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(prediction, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13320,   102],\n",
       "       [ 1491, 10282]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#True Positive (TP) : Observation is positive, and is predicted to be positive.\n",
    "#False Negative (FN) : Observation is positive, but is predicted negative.\n",
    "#True Negative (TN) : Observation is negative, and is predicted to be negative.\n",
    "#False Positive (FP) : Observation is negative, but is predicted positive.\n",
    "\n",
    "TP = 13320\n",
    "FP = 102\n",
    "FN = 1491\n",
    "TN = 10282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   93.6773169279619 %\n"
     ]
    }
   ],
   "source": [
    "Acc = ((TP + TN)/(TP + TN + FP + FN))\n",
    "\n",
    "print( \"Accuracy:  \", Acc * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 99.24005364327225 %\n"
     ]
    }
   ],
   "source": [
    "# Precision\n",
    "\n",
    "PPV = ((TP)/(TP+FP))\n",
    "\n",
    "print(\"Precision\", PPV * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  89.93315778813044 %\n"
     ]
    }
   ],
   "source": [
    "# Recall \n",
    "\n",
    "TPR = ((TP)/(TP + FN))\n",
    "\n",
    "print(\"Recall: \", TPR * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.layers[0].get_weights()[0]\n",
    "\n",
    "biases = model.layers[0].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28720412,  0.18459384,  0.6836856 ,  0.5437398 , -1.1158584 ,\n",
       "        -0.13526447,  1.1648644 ,  0.35779437,  1.5817791 , -1.1692113 ,\n",
       "        -1.2604862 , -1.4834087 ,  1.166839  , -0.30825603, -0.00746316,\n",
       "        -0.25313568, -1.2777485 ,  0.77951   , -0.1757714 ,  0.0735562 ,\n",
       "         0.7033993 ,  1.8283923 ,  0.12341286, -0.04445767,  1.9018486 ,\n",
       "         1.5015203 , -1.8785689 , -1.7643595 , -0.7797831 ,  2.3215919 ,\n",
       "        -0.35191762,  1.11279   ,  0.67243105,  1.114305  ,  1.8636287 ,\n",
       "         2.0455031 ,  0.49507722, -0.61292905, -1.3518962 ,  1.4987679 ,\n",
       "        -1.0255954 ,  2.0280793 , -0.6355088 , -0.7582426 ,  0.20323554,\n",
       "         0.09280744,  1.2911578 ,  1.7514297 ,  2.1036873 , -0.18509501,\n",
       "        -0.36257833, -0.784956  ,  0.09943074,  0.12856203,  0.15979539,\n",
       "         0.1145408 , -0.34507954, -0.20543446,  1.5486424 , -1.3889315 ,\n",
       "        -0.65846896, -0.26617083, -1.6159631 , -1.8031719 , -1.7734059 ,\n",
       "         1.2309023 ,  1.9548002 ,  0.3402118 ,  1.2429622 , -0.77352446,\n",
       "        -0.44981888, -0.15138893,  2.0669324 ,  0.19570865,  0.772351  ,\n",
       "         0.4651975 ,  2.4912724 , -1.0750095 , -0.5792559 , -1.1429154 ,\n",
       "        -0.14605696, -1.3004252 ,  0.9646068 ,  0.09591296,  1.1761295 ,\n",
       "        -1.039364  ,  1.8088979 , -0.3195942 , -0.37347043, -0.98226815,\n",
       "        -0.5672705 , -0.13271722,  0.10390633,  0.21879625, -0.08619035,\n",
       "         0.59630394, -0.7882261 , -0.22236615,  0.7838398 ,  0.09152051,\n",
       "        -0.24189223, -1.0719217 ,  0.19189814, -1.2292775 , -0.84734505,\n",
       "         0.6155616 ,  0.17829528, -0.78757393, -1.6916711 ,  1.820026  ,\n",
       "        -1.1427451 , -0.9422754 ,  0.4980155 ,  1.4423009 ,  1.8964677 ,\n",
       "        -1.0398016 ,  1.6020075 ,  0.1022194 ,  1.9573634 ,  1.1343173 ,\n",
       "         1.9298675 ,  0.16556048, -0.52581215, -1.0541523 ,  1.5738012 ,\n",
       "         0.74833685,  0.15714078, -0.16658346, -0.8581691 , -0.5310938 ,\n",
       "         0.8433808 , -0.37588155,  0.19428864,  0.11261535,  0.18229033,\n",
       "         0.14805125, -0.19116999,  1.1550496 ,  1.7079589 ,  1.3872446 ,\n",
       "        -1.0792196 , -0.8600005 , -0.2913433 , -1.9276421 ,  0.18842046,\n",
       "        -0.4559909 , -1.1507865 , -0.9770877 ,  0.5508793 ,  0.59256905,\n",
       "        -0.5687484 ,  1.377258  ,  0.49256706,  0.60293883,  0.49903858,\n",
       "        -1.7084823 , -0.05083097,  1.4220942 ,  0.9456489 , -1.3076241 ,\n",
       "        -0.1483419 ,  0.39070258,  0.21414925,  0.87582046, -0.00861507,\n",
       "        -0.46391666, -0.16884574, -1.3547431 , -0.3795104 ,  1.6745126 ,\n",
       "         0.34870422,  1.4083257 ,  0.16170762, -0.40466762,  0.06845891,\n",
       "         0.12114701, -0.2041178 ,  0.652014  , -0.12014679, -0.7931325 ,\n",
       "        -0.3066642 , -0.16025236,  1.0504304 ,  1.33368   , -0.01103601,\n",
       "         1.3254645 ,  0.8428425 , -0.26689407,  1.011276  , -0.20990522,\n",
       "         0.09506962,  1.0153545 ,  2.0901568 , -1.6083484 ,  0.582228  ,\n",
       "         0.682487  ,  0.23670265, -0.34930393, -1.2928374 , -0.29180434],\n",
       "       [-1.3169107 ,  0.08473797,  1.3523952 ,  0.3929043 ,  0.13447337,\n",
       "        -0.01430441, -0.19651246,  0.45830724,  1.4229078 ,  1.5467515 ,\n",
       "        -0.9615063 ,  0.27834427, -0.63703007,  1.5205666 ,  0.68736684,\n",
       "         0.9248526 , -0.9519301 ,  1.4283156 , -0.41184574,  1.3410728 ,\n",
       "         0.25155398, -0.45404473, -1.9666336 , -1.1607559 , -1.769209  ,\n",
       "        -0.66246784,  1.2019668 ,  1.1019375 , -0.7508844 ,  0.29096377,\n",
       "         0.0804438 ,  0.09305315,  1.1342424 , -1.1885827 , -0.42258507,\n",
       "        -0.7820935 ,  0.63946605, -1.0602272 ,  1.7015656 ,  0.5606008 ,\n",
       "         1.1481844 , -0.44945937,  0.461604  , -1.2762694 ,  0.02781391,\n",
       "        -1.4361733 ,  0.63158834,  0.21300687, -1.5071582 ,  0.395367  ,\n",
       "        -0.89227307, -0.11227911, -1.7024524 ,  0.37050533,  0.4371802 ,\n",
       "         0.86773705, -1.5951978 ,  1.1582458 , -0.666221  ,  1.1129632 ,\n",
       "         0.56597376,  1.6178949 ,  0.62693447, -2.123247  ,  1.134509  ,\n",
       "        -0.50706047, -1.2550374 , -0.31032264, -2.1085439 ,  0.29655585,\n",
       "         0.07694732, -1.2212056 ,  0.7789779 ,  0.07414526, -1.8541039 ,\n",
       "        -1.0746475 ,  0.67358464,  0.32716492, -1.5619847 ,  0.88359433,\n",
       "        -0.68538547,  1.2098132 , -1.3398887 ,  1.152401  , -0.90841407,\n",
       "         1.0663751 ,  0.06283493, -0.14143948,  0.65362376,  1.4399402 ,\n",
       "        -0.4849091 ,  0.32711658,  1.2517247 , -0.0944244 , -0.02506987,\n",
       "        -1.3164907 , -1.4942611 ,  1.3926929 , -1.9333758 ,  1.0715257 ,\n",
       "        -0.9034516 , -0.43237782,  0.08065425, -0.32064128, -2.1316595 ,\n",
       "         0.6652344 , -2.1158302 , -1.1721761 ,  0.70028305,  0.9666802 ,\n",
       "         2.099083  ,  0.26978847, -0.95953536,  0.17835279,  1.0146226 ,\n",
       "         0.11796746,  1.2399824 ,  1.19019   ,  0.22785074, -0.5563296 ,\n",
       "        -0.43348023,  0.3028391 ,  0.4651141 , -0.78924614,  0.14585988,\n",
       "        -1.7174171 , -1.1321006 , -1.1419239 , -1.1904435 ,  1.3730774 ,\n",
       "         0.7217318 , -0.21464619, -0.43224707, -1.8167137 ,  0.15926027,\n",
       "        -1.4003404 ,  1.3588735 , -0.49072027,  1.8008153 ,  0.38818887,\n",
       "        -0.3157642 , -0.28766075,  1.8168464 ,  0.18889116,  0.18523109,\n",
       "         0.23605673,  0.15389125,  1.2445129 , -1.2113974 ,  0.97751266,\n",
       "         2.125301  ,  0.16687039,  0.93634224, -0.02140037,  1.9906515 ,\n",
       "         0.54910916,  0.7864407 , -1.0481569 , -0.5406709 ,  0.15104555,\n",
       "        -0.01433403, -0.56470174, -2.2998135 ,  1.5652566 ,  0.61843723,\n",
       "         0.32108146,  0.9388284 ,  0.70523113,  1.0285952 ,  0.49614996,\n",
       "         0.45737094,  0.14023882, -0.30742124,  2.034952  ,  1.8658695 ,\n",
       "        -1.459821  ,  0.83489704,  1.2451364 , -1.1207843 , -1.7563494 ,\n",
       "         0.9984255 , -0.00473499, -0.53037536,  1.5303395 ,  0.11797514,\n",
       "        -1.8626877 ,  0.1960161 , -1.9348375 ,  0.04618801,  1.2716154 ,\n",
       "        -1.4315369 , -1.4283172 , -0.92589796,  0.86803323, -1.0533781 ,\n",
       "        -1.613529  , -2.489732  ,  1.6958493 , -0.9706094 ,  0.3849973 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.32066265e-01,  6.48853004e-01, -7.82416575e-03,  4.11361903e-01,\n",
       "       -8.33618641e-02,  7.36425936e-01,  2.71984547e-01,  5.93921483e-01,\n",
       "       -5.77743277e-02,  2.25434694e-02, -1.15262819e-02, -1.79410189e-01,\n",
       "        6.45960048e-02,  3.20991039e-01,  5.39643586e-01,  3.04628879e-01,\n",
       "       -1.38841748e-01, -1.66920815e-02,  3.84423703e-01,  4.80042666e-01,\n",
       "        3.47073317e-01,  4.90949936e-02,  3.56494367e-01,  1.61950976e-01,\n",
       "       -2.21529230e-01, -1.56011460e-02, -3.25005084e-01, -3.71601880e-01,\n",
       "        8.68534669e-02, -1.37280479e-01,  3.50899458e-01,  1.18515082e-02,\n",
       "        6.61302090e-01,  3.66684109e-01,  1.29231662e-01, -1.30690649e-01,\n",
       "        6.16764784e-01, -7.72639140e-02, -2.17217848e-01, -1.34707674e-01,\n",
       "        1.34502962e-01,  1.39880762e-01,  8.35169628e-02, -1.69157058e-01,\n",
       "        7.05611169e-01,  2.74630576e-01, -2.05998093e-01, -1.48949236e-01,\n",
       "       -1.02809720e-01,  3.22972119e-01,  2.19634295e-01,  3.76767926e-02,\n",
       "        2.95078367e-01,  5.29858708e-01,  6.16357386e-01,  5.55018127e-01,\n",
       "       -6.06054589e-02,  3.83310556e-01,  4.74314362e-01, -8.98202956e-02,\n",
       "       -5.42945899e-02,  4.62175488e-01, -8.56320560e-02, -3.72376919e-01,\n",
       "       -3.03104997e-01,  3.51335943e-01, -9.17530507e-02,  3.89057875e-01,\n",
       "       -3.21012102e-02, -7.54656568e-02,  8.38982686e-03,  2.92838439e-02,\n",
       "       -3.02900910e-01,  6.82070613e-01,  4.14470494e-01,  7.93836340e-02,\n",
       "       -8.85158479e-02,  7.92248696e-02, -1.87120959e-01,  6.12692051e-02,\n",
       "        2.28858322e-01, -1.54162543e-02, -1.77294120e-01,  5.10002017e-01,\n",
       "        3.89983244e-02,  8.37662220e-02,  1.67367145e-01,  1.90748066e-01,\n",
       "        3.03463548e-01, -1.35525927e-01,  9.44053009e-02,  4.95834976e-01,\n",
       "        5.47125399e-01,  7.48765588e-01,  7.17453837e-01,  3.81279498e-01,\n",
       "       -2.24421501e-01,  4.20046121e-01,  3.82909715e-01,  5.02410412e-01,\n",
       "        1.26314148e-01,  1.53155804e-01,  6.68396413e-01, -5.13699953e-04,\n",
       "       -2.06031591e-01,  4.26860750e-01,  5.15016139e-01, -2.19677657e-01,\n",
       "       -3.03643763e-01,  3.21152598e-01,  1.62127391e-01,  8.71603191e-02,\n",
       "        4.04293567e-01, -1.24990478e-01, -5.96016757e-02,  1.72257684e-02,\n",
       "       -9.08638015e-02,  5.25213122e-01,  1.37216048e-02,  4.12454963e-01,\n",
       "        2.65290111e-01,  7.22591639e-01, -2.14768443e-02, -5.08425478e-03,\n",
       "        1.52989551e-02,  4.53153968e-01,  4.97651637e-01,  3.98805104e-02,\n",
       "       -1.02176525e-01,  1.92321867e-01,  1.78691328e-01,  4.40244853e-01,\n",
       "        7.08173573e-01,  3.47310811e-01,  6.86843932e-01,  4.57167029e-01,\n",
       "        4.78546411e-01,  3.52777034e-01, -2.41692141e-01,  8.52710158e-02,\n",
       "       -7.62416944e-02, -8.68199244e-02,  5.33825457e-01, -9.38865393e-02,\n",
       "        7.25681603e-01,  3.26187819e-01, -7.84228370e-02,  5.21372445e-02,\n",
       "        3.69578570e-01,  2.03877926e-01,  2.29681879e-01, -2.01846715e-02,\n",
       "        1.54333353e-01,  6.44719899e-01, -1.04516804e-01, -2.97029972e-01,\n",
       "        5.09645462e-01,  7.81888813e-02,  4.70817875e-04, -5.63269388e-03,\n",
       "        8.03433478e-01,  4.30847973e-01,  6.42343104e-01,  2.94127576e-02,\n",
       "        4.82143700e-01,  1.00070037e-01,  4.36233193e-01, -1.90310106e-01,\n",
       "        2.75446504e-01, -4.63769548e-02,  5.88305235e-01,  8.09002891e-02,\n",
       "        5.75178444e-01,  4.35223311e-01,  5.70831299e-01,  3.68914455e-01,\n",
       "        3.69378626e-01,  5.36863029e-01,  8.01493414e-03, -2.15403810e-01,\n",
       "        2.91772962e-01,  6.57116711e-01,  4.05967414e-01, -5.62334806e-02,\n",
       "        6.07546926e-01, -9.37671512e-02,  5.62551796e-01,  4.74714488e-02,\n",
       "        2.87995577e-01,  3.72119665e-01,  2.87082881e-01, -1.28652453e-01,\n",
       "       -3.07163864e-01, -2.10256964e-01,  2.98254609e-01,  3.71538281e-01,\n",
       "        2.70946622e-01,  3.52325499e-01, -2.22132444e-01,  1.17706083e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
